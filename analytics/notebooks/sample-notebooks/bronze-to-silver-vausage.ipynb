{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e0a5598a-993a-4823-bd0a-1d25bd63bdc6"
        }
      },
      "source": [
        "# Send Data from Bronze Table to Silver VAUsage Table\n",
        "To run this notebook, import it into Azure Synapse and attach it to an Apache Spark Pool.      \n",
        "Choose the \"Small\" Node Size, and choose \"3\" as the Number of Nodes.     \n",
        "Be sure to run the \"rate-streaming-to-bronze\" Notebook beforehand, to ensure there is data to pull from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9bc8e1a2-7a06-4c96-b12e-91f2b8ab9628"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "import org.apache.spark.sql.functions._\n",
        "import org.apache.spark.sql.types._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4aff32a6-92ce-4913-aa3e-0f636ff6eb70"
        }
      },
      "source": [
        "## Configure the Storage Account (to read from)\n",
        "Replace the value `<storageAccountName>` with the name of the storage account where the Bronze Delta Table data is stored.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ac8de88e-4cbc-419f-a049-c1adb2017c74"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "val storageAccountName = \"<storageAccountName>\"\n",
        "val bronzeDataLocation: String = \"abfss://datalake@\"+storageAccountName+\".dfs.core.windows.net/bronzeSynapse\"  \n",
        "val silverDataLocation: String = \"abfss://datalake@\"+storageAccountName+\".dfs.core.windows.net/silverSynapse/VAUsage\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "31a46701-1047-43bc-8a49-792b4d996645"
        }
      },
      "source": [
        "## Read the Data\n",
        "Here the data is read from the `bronzeDataLocation` specified in the previous cell, which is configured using the value inputted for `storageAccount`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "020ebe55-5428-47a5-a425-54f75a77de92"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "var bronzeDF = spark.readStream.format(\"delta\").load(bronzeDataLocation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "5a733a3e-606e-41a2-81e9-76ee10c32994"
        }
      },
      "source": [
        "## Parse the Body and Split into Columns\n",
        "The schema of the Dataframe is configured to match the schema of the Silver VAUsage Table. The body is parsed and split into columns.\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "72caa6fb-dc14-48da-b693-cfcac8170af2"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "val silverSchema: StructType = new StructType().add(\"Object\", StringType).add(\"Action\", StringType)\n",
        "\n",
        "var silverDF = bronzeDF.where(\"Properties.topic == 'VAUsage'\")\n",
        "\n",
        "silverDF = silverDF.withColumn(\"Body\", col(\"Body\").cast(StringType)) // cast the \"body\" column to StringType\n",
        "silverDF = silverDF.withColumn(\"JsonBody\", get_json_object(col(\"Body\"), \"$\")) // extracts JSON object from the \"body\" column\n",
        "silverDF = silverDF.withColumn(\"SilverSchemaFields\", from_json(col(\"JsonBody\"), silverSchema)) // returns a struct value with the given JSON string and schema\n",
        "\n",
        "silverDF = silverDF.select(\n",
        "    col(\"ProcessedTimestamp\"),\n",
        "    col(\"ProcessedDate\"),\n",
        "    col(\"ProcessedHour\"),\n",
        "    col(\"UserId\"),\n",
        "    col(\"Properties\"),     \n",
        "    col(\"SilverSchemaFields.*\") // creates a new column for each struct field from 'silverSchema'     \n",
        ")      \n",
        "\n",
        "silverDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "548a6c52-9503-40cd-8ce5-c58aec9a080c"
        }
      },
      "source": [
        "## Write Data to Silver VAUsage Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "822c9e8e-0ba3-4ec9-81d8-98a36802c03b"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "val silverVAUsageQuery = silverDF.writeStream.format(\"delta\").\n",
        "outputMode(\"append\").\n",
        "partitionBy(\"ProcessedDate\", \"ProcessedHour\").\n",
        "option(\"checkpointLocation\", silverDataLocation + \"/checkpoint\").\n",
        "start(silverDataLocation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9eda62b5-77e0-4f5e-872a-f48e49b7d6f0"
        }
      },
      "source": [
        "## Viewing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ac9eb791-0292-4f02-93ed-8be244b549ac"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "var silverViewDF = spark.read.format(\"delta\").load(silverDataLocation)\n",
        "silverViewDF.orderBy(col(\"ProcessedTimestamp\").desc).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b5cca299-4acb-4c65-bfe8-8221621118f4"
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "silverViewDF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "scala"
        },
        "collapsed": false,
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "ProcessedDate"
            ],
            "values": [
              "ProcessedTimestamp"
            ],
            "yLabel": "ProcessedTimestamp",
            "xLabel": "ProcessedDate",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "%%spark\n",
        "display(silverViewDF.orderBy(col(\"ProcessedTimestamp\").desc))"
      ]
    }
  ],
  "metadata": {
    "save_output": false,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}
